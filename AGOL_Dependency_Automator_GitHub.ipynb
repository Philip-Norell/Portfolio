{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5899a754-696d-4111-bbf9-597c60ffe329",
   "metadata": {},
   "source": [
    "AGOL Dependency Automator\n",
    "\n",
    "Purpose: \n",
    "        This script is designed to automate almost all the work involved in creating a comprehensive data lineage for AGOL content.\n",
    "    Moreoever, this script also documents feature services that are not consumed by webmaps for the purposes of data governance. \n",
    "    Ouput data is visualized in a series of Excel sheets formatted as sortable dependency matrices. \n",
    "\n",
    "Method:\n",
    "        There are two avenues of data capture in this script.    \n",
    "    First, it compiles a dictionary of all webmaps in AGOL and parses their related JSONs to extract the services they depend upon. \n",
    "    Those services are then matched to a dictionary of feature services and feature classes, producing a dictionary structured like\n",
    "    {webmap : {service : [feature classes]}}. This is then transformed into a pandas dataframe, transposed, and then written as a \n",
    "    formatted Excel sheet. Second, the same process is performed on a dictionary of experiences, creating a dictionary strucutred as \n",
    "    {experience : {webmap : {service : [feature classes]}}.\n",
    "\n",
    "Inputs:\n",
    "        This script takes inputs from two sources. The first is directly from Portal/AGOL via the ArcGIS API, and the second is a \n",
    "    manually created document detailing which feature classes services consume. The second document must be created and maintained \n",
    "    manually, but such maintenance will only be required infrequently due to how seldom feature classes (as well as referenced services)\n",
    "    are added or removed from SDE. The creation process for the feature class input sheet is detailed in the documentation. \n",
    "\n",
    "Limitations: \n",
    "        This script does not capture which services experiences consume directly without a webmap intermediary.\n",
    "    To my knowledge, this is possible but may be difficult. Therefore, since our standard practice is for experiences to only\n",
    "    consume webmaps, I didn't deem this necessary. Furthermore, the orphan services sheet produced does not account for services\n",
    "    drawn upon by solutions. \n",
    "\n",
    "Misc:\n",
    "        The dictionary-building code chunks will often return error text along the lines of \"Service (ID String) does not exist.\"\n",
    "    These are deleted services that retain their itemID but have all attributes such as title and URL erased. If the ID is plugged \n",
    "    into a standard AGOL/Portal item URL, it will say the service is deleted or unavailable. \n",
    "\n",
    "Documentation location: \"filepath\\Creating Input Data for Dependency Visualizer.docx\"\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225376c1-cb59-4469-8bce-83cff4b5920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import xlsxwriter as xl\n",
    "import numpy as np\n",
    "\n",
    "date = datetime.date.today()\n",
    "formatted_date_mdy = date.strftime(\"%m_%d_%Y\")\n",
    "os.mkdir(fr\"filepath\\AGOL_Dependencies_{formatted_date_mdy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cce26e-4a65-4598-9ea5-5941594db5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports experiences, apps and maps from AGOL and converts them into dictionaries. \n",
    "# Apps are not used in the code, but it could be adapted such that apps replace experiences.\n",
    "# Ai-assisted.\n",
    "\n",
    "ExpTitle = []\n",
    "ExpID = []\n",
    "MapTitle = []\n",
    "MapID = []\n",
    "servtitle = [] \n",
    "servid = []\n",
    "servtype = []\n",
    "servurl = []\n",
    "servowner = []\n",
    "servcreated = []\n",
    "servmod = []\n",
    "servcreated_unix = []\n",
    "servmod_unix = []\n",
    "dashtitle = []\n",
    "dashid = []\n",
    "\n",
    "portal_url = \n",
    "username = \n",
    "password =    \n",
    "\n",
    "try:\n",
    "    gis = GIS(portal_url, username, password)\n",
    "    print(f\"Successfully connected to {gis.properties.portalName}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the portal: {e}\")\n",
    "    exit()\n",
    "\n",
    "web_exps = gis.content.search(query = \"type:Web Experience\", item_type = \"Web Experience\", max_items = 1000)\n",
    "web_maps = gis.content.search(query = \"type:Web Map\", item_type = \"Web Map\", max_items = 1000)\n",
    "feature_services = gis.content.search(query = \"type:Feature Service\", item_type = \"Feature Service\", max_items = 5000)\n",
    "map_services = gis.content.search(query = \"type:Map Service\", item_type = \"Map Service\", max_items = 5000)\n",
    "vector_services = gis.content.search(query = \"type:Vector Tile Service\", item_type = \"Vector Tile Service\", max_items = 5000)\n",
    "dashboards = gis.content.search(query = \"type:Dashboard\", item_type = \"Dashboard\", max_items = 1000)\n",
    "\n",
    "\n",
    "if web_exps:\n",
    "    for web_exp in web_exps:\n",
    "        ExpTitle.append(web_exp.title)\n",
    "        ExpID.append(web_exp.id)\n",
    "else:\n",
    "    print(\"No experiences found in the portal.\")\n",
    "\n",
    "if web_maps:\n",
    "    for web_map in web_maps:\n",
    "        MapTitle.append(web_map.title)\n",
    "        MapID.append(web_map.id)   \n",
    "            \n",
    "else:\n",
    "    print(\"No Web Maps found in the portal.\") \n",
    "\n",
    "if feature_services:\n",
    "    for service in feature_services:\n",
    "        servtitle.append(service.title)\n",
    "        servid.append(service.id)\n",
    "        servtype.append(service.type)\n",
    "        servurl.append(service.url)\n",
    "        servowner.append(service.owner)\n",
    "        servcreated_unix.append(service.created)\n",
    "        servmod_unix.append(service.modified)\n",
    "        \n",
    "if map_services:\n",
    "    for service in map_services:\n",
    "        servtitle.append(service.title)\n",
    "        servid.append(service.id)\n",
    "        servtype.append(service.type)\n",
    "        servurl.append(service.url)\n",
    "        servowner.append(service.owner)\n",
    "        servcreated_unix.append(service.created)\n",
    "        servmod_unix.append(service.modified)\n",
    "        \n",
    "if vector_services:\n",
    "    for service in vector_services:\n",
    "        servtitle.append(service.title)\n",
    "        servid.append(service.id)\n",
    "        servtype.append(service.type)\n",
    "        servurl.append(service.url)\n",
    "        servowner.append(service.owner)\n",
    "        servcreated_unix.append(service.created)\n",
    "        servmod_unix.append(service.modified)\n",
    "\n",
    "if dashboards:\n",
    "    for dashboard in dashboards:\n",
    "        dashtitle.append(dashboard.title)\n",
    "        dashid.append(dashboard.id)\n",
    "\n",
    "        \n",
    "expdict = dict(zip(ExpTitle, ExpID)) \n",
    "mapdict = dict(zip(MapTitle, MapID)) \n",
    "dashdict = dict(zip(dashtitle, dashid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e669b-a06b-40dd-a22d-b09fa0d182bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in servcreated_unix: # Converts unix millisecond timestamp to date\n",
    "    date_s = each / 1000\n",
    "    date = datetime.date.fromtimestamp(date_s)\n",
    "    servcreated.append(date)\n",
    "\n",
    "for each in servmod_unix:\n",
    "    date_s = each / 1000\n",
    "    date = datetime.date.fromtimestamp(date_s)\n",
    "    servmod.append(date)\n",
    "    \n",
    "\n",
    "services_list = [] \n",
    "for name, ID, typ, url, owner, created, modified in zip(servtitle, servid, servtype, servurl, servowner, servcreated, servmod):\n",
    "    string = name + \" | \" + owner + \" | \" + f'{created}' + \" | \" + f'{modified}' + \" | \" + ID + \" | \" + typ + \" | \" + url\n",
    "    services_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c526a73b-bd11-4c74-8bc0-e78edb110241",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_df = pd.read_csv(r\"filepath\\FeatureServiceFeatureClassDependencies.csv\")\n",
    "\n",
    "temp_df = dependency_df.T.values\n",
    "temp_list = []\n",
    "for each in temp_df:\n",
    "    x = []\n",
    "    for val in each:\n",
    "        if val != \"N\":\n",
    "            x.append(val)      \n",
    "    \n",
    "    temp_list.append(x)\n",
    "\n",
    "keylist = []\n",
    "vallist = []\n",
    "for each in temp_list:\n",
    "    key = each[0]\n",
    "    keylist.append(key)\n",
    "    val = each[1:]\n",
    "    vallist.append(val)\n",
    "\n",
    "fc_dict = dict(zip(keylist, vallist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a28b4-d53b-49f2-8842-25fce16f3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Functions\n",
    "\n",
    "# Creates a dictionary of experiences/dashboards and webmaps. Used on the JSONs of dashboards and experiences.\n",
    "# Defining Functions\n",
    "\n",
    "# Creates a dictionary of experiences/dashboards and webmaps. Used on the JSONs of dashboards and experiences.\n",
    "def find_web_maps(data,found_values=None): \n",
    "    if found_values is None:\n",
    "        found_values = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if data.get('type') == 'WEB_MAP':\n",
    "                if 'itemId' in data:\n",
    "                    dep_item = gis.content.get(data['itemId'])\n",
    "                    if dep_item:\n",
    "                        info_str = (f\"{dep_item.title}, Item ID: {dep_item.id}\") \n",
    "                        found_values.append(info_str)\n",
    "            find_web_maps(value,found_values)\n",
    "\n",
    "    \n",
    "    return found_values\n",
    "\n",
    "def dash_find_web_maps(data,found_values=None): \n",
    "    if found_values is None:\n",
    "        found_values = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        if \"itemId\" in data:\n",
    "            \n",
    "            dep_id = data.get('itemId')            \n",
    "            if dep_id is not None:\n",
    "                dep_item = gis.content.get(dep_id)\n",
    "                if dep_item:\n",
    "                    info_str = info_str = (f\"{dep_item.title}, Item ID: {dep_item.id}, {dep_item.type}\")\n",
    "                    found_values.append(info_str)\n",
    "                else:\n",
    "                    print(f'Service {dep_id} does not exist')\n",
    "                    \n",
    "        for key, value in data.items():\n",
    "            dash_find_web_maps(value, found_values)\n",
    "            \n",
    "    elif isinstance(data, list): \n",
    "        for each in data:\n",
    "            dash_find_web_maps(each, found_values)\n",
    "    \n",
    "    return found_values\n",
    "\n",
    "\n",
    "\n",
    "# Recursively searches though map dependency JSON for item IDs and rest service URLs and creates a list of dependencies.\n",
    "# Used within a for loop of web maps.\n",
    "\n",
    "def dependency_recursion(data,found_values=None):\n",
    "    if found_values is None:\n",
    "        found_values = []\n",
    "\n",
    "    if isinstance(data, dict):\n",
    "        if 'itemId' in data:\n",
    "            dep_id = data.get('itemId')\n",
    "            dep_item = gis.content.get(dep_id)\n",
    "            if dep_item:\n",
    "                info_str = (f\"{dep_item.title} || {dep_item.id} || {dep_item.type} || {dep_item.url}\")\n",
    "                found_values.append(info_str)\n",
    "            else:\n",
    "                print(f'Service {dep_id} does not exist')\n",
    "        elif 'url' in data:\n",
    "            info_str = data.get('url')\n",
    "            if r'/image' not in info_str.lower() and r'/mapviewer' not in info_str.lower() and not re.fullmatch(r'[\\w\\W]{32,38}', info_str):\n",
    "                found_values.append(info_str)\n",
    "            \n",
    "        for key, value in data.items():\n",
    "            dependency_recursion(value, found_values)\n",
    "            \n",
    "    elif isinstance(data, list): \n",
    "        for each in data:\n",
    "            dependency_recursion(each, found_values)\n",
    "    \n",
    "    return found_values\n",
    "    \n",
    "# AI-created alphabet generator function\n",
    "def make_alphabet(n):\n",
    "    labels = []\n",
    "    while len(labels) < n:\n",
    "        num = len(labels)\n",
    "        label = \"\"\n",
    "        while True:\n",
    "            num, rem = divmod(num, 26)\n",
    "            label = chr(65 + rem) + label\n",
    "            if num == 0:\n",
    "                break\n",
    "            num -= 1\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "# Xlsxwriter formatting function\n",
    "def create_new_sheet(writer_object, dataframe, sheet_title, index_str):\n",
    "    dataframe = dataframe.fillna(\"\")\n",
    "    dataframe.to_excel(writer, sheet_name = sheet_title)\n",
    "    sheet_id = writer.sheets[sheet_title]\n",
    "    \n",
    "    headers_list = []\n",
    "    for each in dataframe.columns:\n",
    "        headers = {'header' : each}\n",
    "        headers_list.append(headers)    \n",
    "    headers_list[0:0] = [{'header' : index_str}]\n",
    "\n",
    "    alphabet = make_alphabet(len(headers_list))\n",
    "    rowcount = dataframe.shape[0] + 1\n",
    "\n",
    "    sheet_id.add_table(f'A1:{alphabet[-1]}{rowcount}', {'columns' : headers_list})\n",
    "\n",
    "    return sheet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3165087-3af9-4d91-bd50-f289e5febae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts mapdict's keys into a better format for later use\n",
    "templist = []\n",
    "mapdict2 = {}\n",
    "for each in mapdict:\n",
    "    deptemp = gis.content.get(mapdict[each])\n",
    "    infostrtemp = (f\"{deptemp.title}, Item ID: {deptemp.id}\")\n",
    "    templist.append(infostrtemp)\n",
    "    mapdict2[infostrtemp] = mapdict[each]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfc3f0-7c60-4a6f-a3a3-71f6e39e7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dependency_dict = {}\n",
    "for key in mapdict2:\n",
    "    innermost_dict = {}\n",
    "    try:\n",
    "        mapItem = gis.content.get(mapdict2[key]) #finds webmap associated with the id value in mapdict.\n",
    "        dependencies = mapItem.get_data(try_json = True)['operationalLayers'] #returns a dictionary with details on supporting services. try_json is optional but may help convert the data to a dictionary.\n",
    "        dep_info_list = []\n",
    "        \n",
    "        dep_info_list = dependency_recursion(dependencies) #Pulls supporting services out of dependency JSON and adds to list\n",
    "                    \n",
    "        for each in dep_info_list:\n",
    "            match_found = False\n",
    "            for x, y in fc_dict.items():\n",
    "                if x in each:\n",
    "                    innermost_dict[each] = y\n",
    "                    match_found = True\n",
    "                    break\n",
    "                if not match_found:\n",
    "                    innermost_dict[each] = [\"This Service is Hosted on AGOL or is a Raster Image\"]\n",
    "        \n",
    "        map_dependency_dict[key] = innermost_dict #writes keys and values to empty dictionary.\n",
    "    except Exception as e:\n",
    "        print(f'{key} {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7674cd-06ee-4575-81db-f84169367149",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_dependency_dict = {}\n",
    "\n",
    "for key in expdict:\n",
    "    try:\n",
    "        experience = gis.content.get(expdict[key])\n",
    "        func_in = experience.get_data()\n",
    "        final = find_web_maps(func_in)\n",
    "        experience_dependency_dict[key] = final\n",
    "    except Exception as e:\n",
    "        print(f'{key}{e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcaf72c-ff50-4814-8c37-8faf2a67ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a nested dictionary detailing all dependency levels.\n",
    "# The dictionary is formatted as follows: {Experience: {Web Map: {Service: [Feature Class]}}}\n",
    "\n",
    "\n",
    "exp_dependency_dict = {}\n",
    "for key in experience_dependency_dict: #Looping over experiences\n",
    "    inner_dict = {}\n",
    "\n",
    "    \n",
    "    #Finds the dependencies of each webmap associated with each experience    \n",
    "    try:\n",
    "        for webmapval in experience_dependency_dict[key]: #Looping over webmaps corresponding to each experience\n",
    "            innermost_dict = {}\n",
    "            match = re.search(r'ID:\\s*([\\w]+)', webmapval, re.IGNORECASE) #Uses regex matching to extract webmap itemid from the dictionary value.\n",
    "            idtext = match.group(1)\n",
    "            mapItem = gis.content.get(idtext) #Finds webmap associated with the id value\n",
    "            dependencies = mapItem.get_data(try_json = True)['operationalLayers'] #returns a dictionary with details on supporting services. try_json is optional but may help convert the data to a dictionary.\n",
    "        \n",
    "            for depinfo in dependencies: #Looping through the dependency JSON for a single web map\n",
    "                dep_info_list = dependency_recursion(depinfo) #Pulls supporting services out of dependency JSON and adds to list\n",
    "            \n",
    "\n",
    "                # Matches the service feature class dependencies to the feature class dependency dict made from the input csv.\n",
    "                # For every service that matches a url in the csv, the supporting feature classes are added as values.\n",
    "                # This creates the innermost dictionary in the nested dictionary that will be inputted into pyvis.\n",
    "\n",
    "                for each in dep_info_list: #Looping through the services associated with a single web map\n",
    "                    match_found = False\n",
    "                    for x, y in fc_dict.items(): \n",
    "                        if x in each:\n",
    "                            innermost_dict[each] = y\n",
    "                            match_found = True\n",
    "                            break\n",
    "                    if not match_found:\n",
    "                        innermost_dict[each] = [\"This Service is Hosted on AGOL or is a Raster Image\"]\n",
    "                                                                            \n",
    "            inner_dict[f\"{mapItem.title}, Item ID: {mapItem.id}\"] = innermost_dict\n",
    "            \n",
    "        exp_dependency_dict[key] = inner_dict #writes keys and values to empty dictionary.\n",
    "    except Exception as e:\n",
    "        print(f'{key} {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82c4a1-ab86-41c8-bcb8-ca29bf952aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounting for edge cases such as maps with no services, experiences with no maps, etc. \n",
    "\n",
    "for webmap, service in map_dependency_dict.items():\n",
    "    if not service:        \n",
    "        map_dependency_dict[webmap] = {\"This Webmap has no Supporting Services\": [\"No Services Therefore no FCs\"]}\n",
    "for exp, webmap in exp_dependency_dict.items():\n",
    "    if not webmap:\n",
    "        exp_dependency_dict[exp] = {\"This Experience has no Supporting Services\" : {\"Likely no Webmap, Likely no Services\": [\"Likely no Services, Likely no FCs\"]}}\n",
    "for exp, webmap in exp_dependency_dict.items():       \n",
    "    for wmap, service in webmap.items():\n",
    "        if not service: \n",
    "            webmap[wmap] = {\"This Webmap has no Supporting Services\": [\"No Services Therefore no FCs\"]}\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdad564-9667-4df6-ab65-e076378aa70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of dashboard dependency dictionaries. Splits dependencies into flat and heiarchical structures e.g. {dashboard : service} and\n",
    "# {dashboard : {webmap: {service}}}\n",
    "\n",
    "dashboard_map_dependency_dict = {}\n",
    "dashboard_service_dependency_dict = {}\n",
    "\n",
    "\n",
    "for key in dashdict:\n",
    "    temp_map_list = []\n",
    "    temp_service_list = []\n",
    "    try:\n",
    "        dashboard = gis.content.get(dashdict[key])\n",
    "        func_in = dashboard.get_data()\n",
    "        final = find_web_maps(func_in)\n",
    "        for each in final:\n",
    "            if \"Web Map\" in each:\n",
    "                temp_map_list.append(each)\n",
    "                dashboard_map_dependency_dict[key] = temp_map_list\n",
    "            else: \n",
    "                temp_service_list.append(each)\n",
    "                dashboard_service_dependency_dict[key] = temp_service_list\n",
    "    except Exception as e:\n",
    "        print(f'{key}{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2888d61b-e3de-405c-af50-2835471e773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See analogous experience code for notes\n",
    "\n",
    "dash_dependency_dict = {}\n",
    "for key in dashboard_map_dependency_dict: #Looping over experiences\n",
    "    inner_dict = {}\n",
    "\n",
    "    try:\n",
    "        for webmapval in dashboard_map_dependency_dict[key]: #Looping over webmaps corresponding to each experience\n",
    "            innermost_dict = {}\n",
    "            match = re.search(r'ID:\\s*([\\w]+)', webmapval, re.IGNORECASE) #Uses regex matching to extract webmap itemid from the dictionary value.\n",
    "            idtext = match.group(1)\n",
    "            mapItem = gis.content.get(idtext) #Finds webmap associated with the id value\n",
    "            dependencies = mapItem.dependent_upon()['list'] #returns a dictionary with details on supporting services. try_json is optional but may help convert the data to a dictionary.              \n",
    "            dep_info_list = dependency_recursion(dependencies) #Pulls supporting services out of dependency JSON and adds to list\n",
    "\n",
    "            for each in dep_info_list: #Looping through the services associated with a single web map\n",
    "                match_found = False\n",
    "                for x, y in fc_dict.items(): \n",
    "                    if x in each:\n",
    "                        innermost_dict[each] = y\n",
    "                        match_found = True\n",
    "                        break\n",
    "                if not match_found:\n",
    "                    innermost_dict[each] = [\"This Service is Hosted on AGOL or is a Raster Image\"]\n",
    "                                                                            \n",
    "            inner_dict[f\"{mapItem.title}, Item ID: {mapItem.id}\"] = innermost_dict\n",
    "            \n",
    "        dash_dependency_dict[key] = inner_dict #writes keys and values to empty dictionary.\n",
    "    except Exception as e:\n",
    "        print(f'{key} {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a2684-6b2b-4556-8c1b-2b18113db4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_service_dict = {}\n",
    "temp_dash_service_dict = {}\n",
    "final_dash_service_dict = {}\n",
    "\n",
    "for dash, webmap in dash_dependency_dict.items():\n",
    "    for wmap, service in webmap.items():\n",
    "        dash_service_dict[dash] = service\n",
    "\n",
    "for dash, service, in dashboard_service_dependency_dict.items():\n",
    "    for serv in service:\n",
    "        temp_dash_service_dict[dash] = {serv : ['This Service is Hosted on AGOL or is a Raster Image']}\n",
    "\n",
    "for dashboard, service in dash_service_dict.items():\n",
    "    final_dash_service_dict[dashboard] = service\n",
    "    for dash, serv in temp_dash_service_dict.items():\n",
    "        if dash not in final_dash_service_dict.keys():\n",
    "            final_dash_service_dict[dash] = serv\n",
    "\n",
    "            \n",
    "for dashboard, service in dash_service_dict.items():\n",
    "    final_dash_service_dict[dashboard] = service\n",
    "    for dash, serv in temp_dash_service_dict.items():        \n",
    "        if dashboard == dash:\n",
    "            service.update(serv)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d40b7e-3cb7-4002-ac09-20f4f11c31ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of dependency matrix pandas dataframe from dependency dicts\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\") #dtype must be object to avoid errors\n",
    "\n",
    "# for every service and fc, creates an index value if not seen before and creates an \"x\" at their intersection. If seen, just creates \"x\" at intersection.\n",
    "for webmap, service in map_dependency_dict.items(): \n",
    "    if service:\n",
    "        for serv, fc in service.items():\n",
    "            empty_df.loc[serv, fc] = \"x\" \n",
    "empty_df = empty_df.replace(b\"\", np.nan) #removes blank anomalies\n",
    "serv_fc_df = empty_df.copy() #consolidates the cells within memory\n",
    "serv_fc_df_t = serv_fc_df.transpose()\n",
    "\n",
    "\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for webmap, service in map_dependency_dict.items():\n",
    "    if service:\n",
    "        for serv, fc in service.items():\n",
    "            empty_df.loc[webmap, fc] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "map_fc_df = empty_df.copy()\n",
    "map_fc_df_t = map_fc_df.transpose()\n",
    "\n",
    "\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for exp, webmap in exp_dependency_dict.items():\n",
    "    if webmap:\n",
    "        for wmap, service in webmap.items():\n",
    "            for serv, fc in service.items():\n",
    "                empty_df.loc[exp, fc] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "exp_fc_df = empty_df.copy()\n",
    "exp_fc_df_t = exp_fc_df.transpose()\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for dash, webmap in dash_dependency_dict.items():\n",
    "    for wmap, service in webmap.items():\n",
    "        for serv, fc in service.items():\n",
    "            empty_df.loc[dash, fc] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "dash_fc_df = empty_df.copy()\n",
    "dash_fc_df_t = dash_fc_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78a162-f5ae-4808-8c5d-3e5c6a3fbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(fr\"filepath\\AGOL_Dependencies_{formatted_date_mdy}\\Feature Class Dependencies.xlsx\", \n",
    "    engine='xlsxwriter')\n",
    "\n",
    "sheet1 = create_new_sheet(writer, serv_fc_df, \"Services by FC\", \"Services\")\n",
    "sheet2 = create_new_sheet(writer, serv_fc_df_t, \"FCs by Services\", \"Feature Classes\")\n",
    "sheet3 = create_new_sheet(writer, map_fc_df, \"Webmaps by FC\", \"Webmaps\")\n",
    "sheet4 = create_new_sheet(writer, map_fc_df_t, \"FCs by Webmap\", \"Feature Classes\")\n",
    "sheet5 = create_new_sheet(writer, exp_fc_df, \"Experiences by FC\", \"Experiences\")\n",
    "sheet6 = create_new_sheet(writer, exp_fc_df_t, \"FCs by Experience\", \"Feature Classes\")\n",
    "sheet7 = create_new_sheet(writer, dash_fc_df, \"Dashboards by FC\", \"Experiences\")\n",
    "sheet8 = create_new_sheet(writer, dash_fc_df_t, \"FCs by Dashboard\", \"Feature Classes\")\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483756e-5874-4266-8315-4003d4b7da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for webmap, service in map_dependency_dict.items():\n",
    "    if service:\n",
    "        for serv, fc in service.items():\n",
    "            empty_df.loc[webmap, serv] = \"x\"\n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "map_serv_df = empty_df.copy()\n",
    "map_serv_df_t = map_serv_df.transpose()\n",
    "\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for exp, webmap in exp_dependency_dict.items():\n",
    "    if webmap:\n",
    "        for wmap, service in webmap.items():\n",
    "            if service:\n",
    "                for serv, fc in service.items():\n",
    "                    empty_df.loc[exp, serv] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "exp_serv_df = empty_df.copy()\n",
    "exp_serv_df_t = exp_serv_df.transpose()\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for dash, service in final_dash_service_dict.items():\n",
    "    for serv, fc in service.items():\n",
    "            empty_df.loc[dash, serv] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "dash_serv_df = empty_df.copy()\n",
    "dash_serv_df_t = dash_serv_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e16232-07f6-4b24-ae93-4b3b2ca0f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(fr\"filepath\\AGOL_Dependencies_{formatted_date_mdy}\\Feature Service Dependencies.xlsx\", \n",
    "    engine='xlsxwriter')\n",
    "\n",
    "sheet1 = create_new_sheet(writer, map_serv_df, \"Webmaps by Service\", \"Webmaps\")\n",
    "sheet2 = create_new_sheet(writer, map_serv_df_t, \"Services by Webmap\", \"Services\")\n",
    "sheet3 = create_new_sheet(writer, exp_serv_df, \"Experiences by Service\", \"Experiences\")\n",
    "sheet4 = create_new_sheet(writer, exp_serv_df_t, \"Services by Experience\", \"Services\")\n",
    "sheet5 = create_new_sheet(writer, dash_serv_df, \"Dashboards by Service\", \"Dashboards\")\n",
    "sheet6 = create_new_sheet(writer, dash_serv_df_t, \"Services by Dashboard\", \"Services\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9bf2a-2805-4514-b805-45d023eb84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for exp, webmap in exp_dependency_dict.items():\n",
    "    if webmap:\n",
    "        for wmap, service in webmap.items():\n",
    "            empty_df.loc[exp, wmap] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "exp_map_df = empty_df.copy()\n",
    "exp_map_df_t = exp_map_df.transpose()\n",
    "\n",
    "empty_df = pd.DataFrame(dtype = \"object\")\n",
    "\n",
    "for dash, webmap in dash_dependency_dict.items():\n",
    "    for wmap, service in webmap.items():\n",
    "            empty_df.loc[dash, wmap] = \"x\"        \n",
    "empty_df = empty_df.replace(b\"\", np.nan)\n",
    "dash_map_df = empty_df.copy()\n",
    "dash_map_df_t = dash_map_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c143e1-5b2d-43ae-983e-3d36ff2eb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(fr\"filepath\\AGOL_Dependencies_{formatted_date_mdy}\\Webmap Dependencies.xlsx\", \n",
    "    engine='xlsxwriter')\n",
    "\n",
    "sheet1 = create_new_sheet(writer, exp_map_df, \"Experiences by Webmap\", \"Experiences\")\n",
    "sheet2 = create_new_sheet(writer, exp_map_df_t, \"Webmaps by Experience\", \"Webmaps\")\n",
    "sheet3 = create_new_sheet(writer, dash_map_df, \"Dashboards by Webmap\", \"Dashboards\")\n",
    "sheet4 = create_new_sheet(writer, dash_map_df_t, \"Webmaps by Dashboards\", \"Webmaps\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a116044-51d1-4fa6-a352-0d73e2dd97dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a an Excel sheet showing feature, map, and vector tile services that are not consumed by webmaps, experiences, or dashboards.\n",
    "\n",
    "orphan_services = [] \n",
    "temp_orphan_list = []\n",
    "duplicate_list =[]\n",
    "duplicate_list2 = []\n",
    "for each in servid: # Ruling out services consumed by webmaps.\n",
    "   if all(each not in serv for webmap, service in map_dependency_dict.items() for serv, fc in service.items()):\n",
    "        duplicate_list.append(each)\n",
    "\n",
    "for each in duplicate_list: # Ruling out services that aren't consumed by webmaps but are consumed by dashbaords.\n",
    "    if all(each not in serv for dashboard, service in dashboard_service_dependency_dict.items() for serv in service):\n",
    "        duplicate_list2.append(each)\n",
    "        \n",
    "for each in duplicate_list2: # Removes duplicates.\n",
    "    if each not in orphan_services:\n",
    "        temp_orphan_list.append(each)\n",
    "        \n",
    "for each in services_list:\n",
    "    if any(servid in each for servid in temp_orphan_list):\n",
    "        if \"cityworks\" not in each.lower():\n",
    "            orphan_services.append(each)  \n",
    "\n",
    "orphan_df = pd.DataFrame(orphan_services)\n",
    "\n",
    "writer = pd.ExcelWriter(fr\"filepath\\AGOL_Dependencies_{formatted_date_mdy}\\Orphan Services.xlsx\", \n",
    "    engine='xlsxwriter')\n",
    "orphan_df.to_excel(writer, sheet_name = \"Sheet_1\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b8ac9e-1ee0-460d-857d-9c2494b47908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
